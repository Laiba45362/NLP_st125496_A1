{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://nlpst125496a1-tdkajvczf4ah4ifbqskmcu.streamlit.app/ deployment link for A! nlp\n"
      ],
      "metadata": {
        "id": "OtPBjl7hj4za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkeIHXojcjBb",
        "outputId": "1eb1a6da-f399-4ebb-d89e-a243d166c6d8"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RkUECvAcjzM",
        "outputId": "7ac25e24-a82f-4807-d606-3049b283ce66"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "id": "n7HC38qOcnRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L-y1uUdU16t",
        "outputId": "a21dd0b8-976e-418f-c136-d63db55f26e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import nltk\n",
        "nltk.download('brown')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.__version__, torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPwuobKpcg00",
        "outputId": "a13df3ea-bffe-40bb-cc65-0a0518d7c3d4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.26.4', '2.5.1+cu121')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib\n",
        "matplotlib.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Fay8IgUAVFkv",
        "outputId": "64b076c6-0f5e-46d9-ff56-b2ee8ccab6dd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.10.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.corpus import brown\n",
        "\n",
        "# Create a corpus containing only documents from the 'earn' category\n",
        "corpus = brown.sents()\n",
        "\n",
        "# Limit the corpus to the first 1000 sentences for demonstration purposes\n",
        "corpus = [[word.lower() for word in sentence] for sentence in corpus]\n",
        "corpus = corpus[:1000]"
      ],
      "metadata": {
        "id": "7rD9kNV7VF2y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get word sequences and unique words\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "vocab = list(set(flatten(corpus)))"
      ],
      "metadata": {
        "id": "M2EW48SEVGJu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "len(vocab)"
      ],
      "metadata": {
        "id": "7Xwuwso0VGgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60bd7836-2e07-4310-a1c0-3745dbc70235"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4272"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#numericalization\n",
        "word2index = {w: i for i, w in enumerate(vocab)}\n",
        "#vocab size\n",
        "voc_size = len(vocab)\n",
        "print(voc_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cnx5AYJcdA4y",
        "outputId": "24f7290a-0c6f-434f-a503-4fc3319b330a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#append UNK\n",
        "vocab.append('<UNK>')\n",
        "word2index['<UNK>'] = 0\n",
        "#just in case we need to use\n",
        "index2word = {v:k for k, v in word2index.items()}"
      ],
      "metadata": {
        "id": "1mZyRrIXdC0G"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "# index the corpus\n",
        "X_i = Counter(flatten(corpus))\n",
        "skip_grams = []\n",
        "# Prepare the skipgram\n",
        "\n",
        "for doc in corpus:\n",
        "    # The skipgram has a window size of 2\n",
        "    for i in range(2, len(doc)-2):\n",
        "        center = doc[i]\n",
        "        outside = [doc[i-1], doc[i+1],doc[i+2],doc[i-2]]\n",
        "        for each_out in outside:\n",
        "            skip_grams.append((center, each_out))\n",
        "X_ik_skipgrams = Counter(skip_grams)\n",
        "def weighting(w_i, w_j, X_ik):\n",
        "\n",
        "    #check whether the co-occurences between w_i and w_j is available\n",
        "    try:\n",
        "        x_ij = X_ik[(w_i, w_j)]\n",
        "        #if not exist, then set to 1 \"laplace smoothing\"\n",
        "    except:\n",
        "        x_ij = 1\n",
        "\n",
        "    #set xmax\n",
        "    x_max = 100\n",
        "    #set alpha\n",
        "    alpha = 0.75\n",
        "\n",
        "    #if co-ocurrence does not exceeed xmax, then just multiply with some alpha\n",
        "    if x_ij < x_max:\n",
        "        result = (x_ij / x_max)**alpha\n",
        "    #otherwise, set to 1\n",
        "    else:\n",
        "        result = 1\n",
        "\n",
        "    return result\n",
        "from itertools import combinations_with_replacement\n",
        "\n",
        "X_ik = {}  # for keeping the co-occurrences\n",
        "weighting_dic = {}  # scaling the percentage of sampling\n",
        "\n",
        "for bigram in combinations_with_replacement(vocab, 2):\n",
        "    if X_ik_skipgrams.get(bigram) is not None:  # matches\n",
        "        co_occer = X_ik_skipgrams[bigram]  # get the count from what we already counted\n",
        "        X_ik[bigram] = co_occer + 1  # + 1 for stability issue\n",
        "        X_ik[(bigram[1], bigram[0])] = co_occer + 1  # count also for the opposite\n",
        "        # print(X_ik[(bigram[1], bigram[0])])  # count also for the opposite\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    weighting_dic[bigram] = weighting(bigram[0], bigram[1], X_ik)\n",
        "    weighting_dic[(bigram[1], bigram[0])] = weighting(bigram[1], bigram[0], X_ik)"
      ],
      "metadata": {
        "id": "PI9kohq5dFCK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create pairs of center word, and outside word\n",
        "\n",
        "def random_batch(batch_size, corpus, window_size=2):\n",
        "    skipgrams = []\n",
        "    for doc in corpus:\n",
        "        for i in range(window_size, len(doc)-window_size):\n",
        "            center = word2index[doc[i]]\n",
        "            outside = [word2index[doc[i-j]] for j in range(-window_size, window_size+1) if j != 0]\n",
        "            for each_out in outside:\n",
        "                skipgrams.append([center, each_out])\n",
        "\n",
        "    random_index = np.random.choice(range(len(skipgrams)), batch_size, replace=False)\n",
        "    inputs, labels = [], []\n",
        "    for index in random_index:\n",
        "        inputs.append([skipgrams[index][0]])\n",
        "        labels.append([skipgrams[index][1]])\n",
        "\n",
        "    return np.array(inputs), np.array(labels)\n",
        "\n",
        "\n",
        "x, y = random_batch(2, corpus)\n",
        "import math\n",
        "\n",
        "def random_batch_glove(batch_size, word_sequence, skip_grams, X_ik, weighting_dic):\n",
        "\n",
        "    #convert to id since our skip_grams is word, not yet id\n",
        "    skip_grams_id = [(word2index[skip_gram[0]], word2index[skip_gram[1]]) for skip_gram in skip_grams]\n",
        "\n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_coocs  = []\n",
        "    random_weightings = []\n",
        "    random_index = np.random.choice(range(len(skip_grams_id)), batch_size, replace=False) #randomly pick without replacement\n",
        "\n",
        "    for i in random_index:\n",
        "        random_inputs.append([skip_grams_id[i][0]])  # target, e.g., 2\n",
        "        random_labels.append([skip_grams_id[i][1]])  # context word, e.g., 3\n",
        "\n",
        "        #get cooc\n",
        "        pair = skip_grams[i]\n",
        "        try:\n",
        "            cooc = X_ik[pair]\n",
        "        except:\n",
        "            cooc = 1\n",
        "        random_coocs.append([math.log(cooc)])\n",
        "\n",
        "        #get weighting\n",
        "        weighting = weighting_dic[pair]\n",
        "        random_weightings.append([weighting])\n",
        "\n",
        "    return np.array(random_inputs), np.array(random_labels), np.array(random_coocs), np.array(random_weightings)\n",
        "x.shape  #batch_size, 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlXrPxSrdapC",
        "outputId": "0c265deb-1981-44a6-bca7-5a198597e134"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ9XZmgMdkuU",
        "outputId": "0a15d052-c50e-4d24-f47b-fca259729e5e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 902],\n",
              "       [1091]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P77kUUGDdpdu",
        "outputId": "e6647b1b-c1fa-47b8-c599-ea4b32be36bd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndEWe9QqdrVe",
        "outputId": "7ad2204f-14e7-4b9f-8f04-caab0ac6208b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4273"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = nn.Embedding(63314, 2)\n",
        "x_tensor = torch.LongTensor(x)\n",
        "embedding(x_tensor).shape  #(batch_size, 1, emb_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_smQezM8dtJA",
        "outputId": "90713cac-b704-48cc-bdc0-ddae21f5fa11"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Skipgram(nn.Module):\n",
        "\n",
        "    def __init__(self, voc_size, emb_size):\n",
        "        super(Skipgram, self).__init__()\n",
        "        self.embedding_center  = nn.Embedding(voc_size, emb_size)\n",
        "        self.embedding_outside = nn.Embedding(voc_size, emb_size)\n",
        "\n",
        "    def forward(self, center, outside, all_vocabs):\n",
        "        center_embedding     = self.embedding_center(center)  #(batch_size, 1, emb_size)\n",
        "        outside_embedding    = self.embedding_center(outside) #(batch_size, 1, emb_size)\n",
        "        all_vocabs_embedding = self.embedding_center(all_vocabs) #(batch_size, voc_size, emb_size)\n",
        "\n",
        "        top_term = torch.exp(outside_embedding.bmm(center_embedding.transpose(1, 2)).squeeze(2))\n",
        "        #batch_size, 1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) = (batch_size, 1)\n",
        "\n",
        "        lower_term = all_vocabs_embedding.bmm(center_embedding.transpose(1, 2)).squeeze(2)\n",
        "        #batch_size, voc_size, emb_size) @ (batch_size, emb_size, 1) = (batch_size, voc_size, 1) = (batch_size, voc_size)\n",
        "\n",
        "        lower_term_sum = torch.sum(torch.exp(lower_term), 1)  #(batch_size, 1)\n",
        "\n",
        "        loss = -torch.mean(torch.log(top_term / lower_term_sum))  #scalar\n",
        "\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "Pf2HxiY8dwd8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipgramNegSampling(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, emb_size):\n",
        "        super(SkipgramNegSampling, self).__init__()\n",
        "        self.embedding_center = nn.Embedding(vocab_size, emb_size) # center embedding\n",
        "        self.embedding_outside = nn.Embedding(vocab_size, emb_size) # out embedding\n",
        "        self.logsigmoid = nn.LogSigmoid()\n",
        "\n",
        "    def forward(self, center_words, target_words, negative_words):\n",
        "        center_embeds = self.embedding_center(center_words) # [batch_size, 1, emb_size]\n",
        "        target_embeds = self.embedding_outside(target_words) # [batch_size, 1, emb_size]\n",
        "        neg_embeds    = -self.embedding_outside(negative_words) # [batch_size, num_neg, emb_size]\n",
        "\n",
        "        positive_score = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
        "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
        "\n",
        "        negative_score = neg_embeds.bmm(center_embeds.transpose(1, 2))\n",
        "        #[batch_size, k, emb_size] @ [batch_size, emb_size, 1] = [batch_size, k, 1]\n",
        "\n",
        "        loss = self.logsigmoid(positive_score) + torch.sum(self.logsigmoid(negative_score), 1)\n",
        "\n",
        "        return -torch.mean(loss)\n",
        "\n",
        "    def prediction(self, inputs):\n",
        "        embeds = self.embedding_v(inputs)\n",
        "\n",
        "        return embeds"
      ],
      "metadata": {
        "id": "nyvh7YuedybI"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Glove(nn.Module):\n",
        "\n",
        "    def __init__(self, voc_size, emb_size):\n",
        "        super(Glove, self).__init__()\n",
        "        self.embedding_center  = nn.Embedding(voc_size, emb_size)\n",
        "        self.embedding_outside = nn.Embedding(voc_size, emb_size)\n",
        "\n",
        "        self.center_bias       = nn.Embedding(voc_size, 1)\n",
        "        self.outside_bias      = nn.Embedding(voc_size, 1)\n",
        "\n",
        "    def forward(self, center, outside, coocs, weighting):\n",
        "        center_embeds  = self.embedding_center(center) #(batch_size, 1, emb_size)\n",
        "        outside_embeds = self.embedding_outside(outside) #(batch_size, 1, emb_size)\n",
        "\n",
        "        center_bias    = self.center_bias(center).squeeze(1)\n",
        "        target_bias    = self.outside_bias(outside).squeeze(1)\n",
        "\n",
        "        inner_product  = outside_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
        "        #(batch_size, 1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) = (batch_size, 1)\n",
        "\n",
        "        loss = weighting * torch.pow(inner_product + center_bias + target_bias - coocs, 2)\n",
        "\n",
        "        return torch.sum(loss)"
      ],
      "metadata": {
        "id": "_W6TTQbbd44k"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2z5oZ4zd7e5",
        "outputId": "38292f13-e667-4d88-9b6d-d7f9c8f23ff6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.test.utils import datapath\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "# Update the file path to the location of your downloaded file\n",
        "glove_file = '/content/glove.6B.100d.txt' # Example: 'data/glove.6B.100d.txt'\n",
        "\n",
        "# Load the GloVe embeddings\n",
        "model_gensim = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True)"
      ],
      "metadata": {
        "id": "hp-piorreAUl"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare all vocab of batch - 2 , vocab - 2 and embed - 2\n",
        "\n",
        "batch_size = 2\n",
        "voc_size   = len(vocab)\n",
        "emb_size = 2\n",
        "\n",
        "def prepare_sequence(seq, word2index):\n",
        "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
        "    return torch.LongTensor(idxs)\n",
        "\n",
        "all_vocabs = prepare_sequence(list(vocab), word2index).expand(batch_size, voc_size)\n",
        "all_vocabs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFIVidDSeb2Y",
        "outputId": "9cc03bd4-d212-4c27-cbf4-e793255fe043"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   0,    1,    2,  ..., 4270, 4271,    0],\n",
              "        [   0,    1,    2,  ..., 4270, 4271,    0]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_skipgram_positive = Skipgram(voc_size, emb_size)\n",
        "model_skipgram_positive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-O9eZaAeDCs",
        "outputId": "9b1b60b9-2f17-490d-89df-16e91195ab22"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Skipgram(\n",
              "  (embedding_center): Embedding(4273, 2)\n",
              "  (embedding_outside): Embedding(4273, 2)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_glove = Glove(voc_size, emb_size)\n",
        "model_glove"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pms9OcjzekjW",
        "outputId": "d9b8f019-0393-435a-ff26-e4a84628bc39"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Glove(\n",
              "  (embedding_center): Embedding(4273, 2)\n",
              "  (embedding_outside): Embedding(4273, 2)\n",
              "  (center_bias): Embedding(4273, 1)\n",
              "  (outside_bias): Embedding(4273, 1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_skipgram_negative = Skipgram(voc_size, emb_size)\n",
        "model_skipgram_negative"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3sOgLyZemlb",
        "outputId": "9efc3f60-6c44-487a-d669-d5809d0dc542"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Skipgram(\n",
              "  (embedding_center): Embedding(4273, 2)\n",
              "  (embedding_outside): Embedding(4273, 2)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.LongTensor(x)\n",
        "label_tensor = torch.LongTensor(y)\n",
        "loss_skipgram_positive = model_skipgram_positive(input_tensor, label_tensor, all_vocabs)\n",
        "loss_skipgram_negative = model_skipgram_negative(input_tensor, label_tensor, all_vocabs)\n",
        "# x, y, cooc, weighting = random_batch_glove(batch_size, corpus, skip_grams, X_ik, weighting_dic)\n",
        "\n",
        "# loss_glove = model_glove(torch.LongTensor(x), torch.LongTensor(y), torch.LongTensor(cooc), torch.LongTensor(weighting))\n",
        "batch_size = 2\n",
        "emb_size   = 2\n",
        "model_skipgram_positive      = Skipgram(voc_size, emb_size)\n",
        "optimizer_skipgram_positive  = optim.Adam(model_skipgram_positive.parameters(), lr=0.001)\n",
        "optimizer_skipgram_negative  = optim.Adam(model_skipgram_negative.parameters(), lr=0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_glove = optim.Adam(model_glove.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "F6QzWlwqepKz"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "num_epochs = 10\n",
        "total_start = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    #get batch\n",
        "    input_batch, label_batch = random_batch(batch_size, corpus)\n",
        "\n",
        "    input_tensor = torch.LongTensor(input_batch)\n",
        "    label_tensor = torch.LongTensor(label_batch)\n",
        "\n",
        "    #predict\n",
        "    loss_skipgram_positive = model_skipgram_positive(input_tensor, label_tensor, all_vocabs)\n",
        "\n",
        "    #backprogate\n",
        "    optimizer_skipgram_positive.zero_grad()\n",
        "    loss_skipgram_positive.backward()\n",
        "\n",
        "    #update alpha\n",
        "    optimizer_skipgram_positive.step()\n",
        "    end = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "\n",
        "    #print the loss_skipgram_positive\n",
        "    # if (epoch + 1) % 1000 == 0:\n",
        "    print(\"Positive Skigram\")\n",
        "    print(f\"Epoch {epoch+1:6.0f} | Loss: {loss_skipgram_positive:2.6f}| time: {epoch_mins}m {epoch_secs}s\")\n",
        "# Record the ending time\n",
        "total_end = time.time()\n",
        "\n",
        "# Calculate and print the total runtime\n",
        "total_runtime = total_end - total_start\n",
        "print(f\"Total runtime: {total_runtime:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oykadpc_erda",
        "outputId": "0f74d8fb-4347-44b4-def9-2f5947f346dc"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive Skigram\n",
            "Epoch      1 | Loss: 11.653115| time: 0m 0s\n",
            "Positive Skigram\n",
            "Epoch      2 | Loss: 9.482544| time: 0m 0s\n",
            "Positive Skigram\n",
            "Epoch      3 | Loss: 8.708591| time: 0m 0s\n",
            "Positive Skigram\n",
            "Epoch      4 | Loss: 12.809539| time: 0m 0s\n",
            "Positive Skigram\n",
            "Epoch      5 | Loss: 11.264104| time: 0m 0s\n",
            "Positive Skigram\n",
            "Epoch      6 | Loss: 8.641483| time: 0m 0s\n",
            "Positive Skigram\n",
            "Epoch      7 | Loss: 9.608809| time: 0m 0s\n",
            "Positive Skigram\n",
            "Epoch      8 | Loss: 9.716224| time: 0m 0s\n",
            "Positive Skigram\n",
            "Epoch      9 | Loss: 8.970243| time: 0m 0s\n",
            "Positive Skigram\n",
            "Epoch     10 | Loss: 9.589486| time: 0m 0s\n",
            "Total runtime: 3.34 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "\n",
        "total_start = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    #get batch\n",
        "    input_batch, label_batch = random_batch(batch_size, corpus)\n",
        "\n",
        "    input_tensor = torch.LongTensor(input_batch)\n",
        "    label_tensor = torch.LongTensor(label_batch)\n",
        "\n",
        "    #predict\n",
        "    loss_skipgram_negative = model_skipgram_negative(input_tensor, label_tensor, all_vocabs)\n",
        "\n",
        "    #backprogate\n",
        "    optimizer_skipgram_negative.zero_grad()\n",
        "    loss_skipgram_negative.backward()\n",
        "\n",
        "    #update alpha\n",
        "    optimizer_skipgram_negative.step()\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "\n",
        "    #print the loss_skipgram_positive\n",
        "    # if (epoch + 1) % 1000 == 0:\n",
        "    print(\"Negative Skigram\")\n",
        "    print(f\"Epoch {epoch+1:6.0f} | Loss: {loss_skipgram_negative:2.6f} | time: {epoch_mins}m {epoch_secs}s\")\n",
        "# Record the ending time\n",
        "total_end = time.time()\n",
        "\n",
        "# Calculate and print the total runtime\n",
        "total_runtime = total_end - total_start\n",
        "print(f\"Total runtime: {total_runtime:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDLICWbVet7x",
        "outputId": "89baa3a1-e30d-440d-f8aa-a9046acf66da"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative Skigram\n",
            "Epoch      1 | Loss: 10.732460 | time: 0m 0s\n",
            "Negative Skigram\n",
            "Epoch      2 | Loss: 13.239696 | time: 0m 0s\n",
            "Negative Skigram\n",
            "Epoch      3 | Loss: 8.504290 | time: 0m 0s\n",
            "Negative Skigram\n",
            "Epoch      4 | Loss: 8.295382 | time: 0m 0s\n",
            "Negative Skigram\n",
            "Epoch      5 | Loss: 9.653572 | time: 0m 0s\n",
            "Negative Skigram\n",
            "Epoch      6 | Loss: 10.702156 | time: 0m 0s\n",
            "Negative Skigram\n",
            "Epoch      7 | Loss: 8.075811 | time: 0m 0s\n",
            "Negative Skigram\n",
            "Epoch      8 | Loss: 9.750718 | time: 0m 0s\n",
            "Negative Skigram\n",
            "Epoch      9 | Loss: 10.116529 | time: 0m 0s\n",
            "Negative Skigram\n",
            "Epoch     10 | Loss: 8.164597 | time: 0m 0s\n",
            "Total runtime: 2.25 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    #get batch\n",
        "    input_batch, label_batch = random_batch(batch_size, corpus)\n",
        "\n",
        "    input_batch, target_batch, cooc_batch, weighting_batch = random_batch_glove(batch_size, corpus, skip_grams, X_ik, weighting_dic)\n",
        "    input_batch  = torch.LongTensor(input_batch)         #[batch_size, 1]\n",
        "    target_batch = torch.LongTensor(target_batch)        #[batch_size, 1]\n",
        "    cooc_batch   = torch.FloatTensor(cooc_batch)         #[batch_size, 1]\n",
        "    weighting_batch = torch.FloatTensor(weighting_batch)\n",
        "\n",
        "    #predict\n",
        "    loss_glove = model_glove(input_batch, target_batch, cooc_batch, weighting_batch)\n",
        "\n",
        "    #backprogate\n",
        "    optimizer_glove.zero_grad()\n",
        "    loss_glove.backward()\n",
        "\n",
        "    #update alpha\n",
        "    optimizer_glove.step()\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "\n",
        "    #print the loss_skipgram_positive\n",
        "    # if (epoch + 1) % 1000 == 0:\n",
        "    print(\"Glove\")\n",
        "    print(f\"Epoch {epoch+1:6.0f} | Loss: {loss_glove:2.6f} | time: {epoch_mins}m {epoch_secs}s\")\n",
        "total_runtime = total_end - total_start\n",
        "print(f\"Total runtime: {total_runtime:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcE4JHZ-ewbe",
        "outputId": "cfa7d9f8-6371-4c3c-8feb-f034cc77630e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Glove\n",
            "Epoch      1 | Loss: 0.301950 | time: 0m 0s\n",
            "Glove\n",
            "Epoch      2 | Loss: 0.744301 | time: 0m 0s\n",
            "Glove\n",
            "Epoch      3 | Loss: 0.144401 | time: 0m 0s\n",
            "Glove\n",
            "Epoch      4 | Loss: 0.296871 | time: 0m 0s\n",
            "Glove\n",
            "Epoch      5 | Loss: 20.829521 | time: 0m 0s\n",
            "Glove\n",
            "Epoch      6 | Loss: 9.774280 | time: 0m 0s\n",
            "Glove\n",
            "Epoch      7 | Loss: 0.580990 | time: 0m 0s\n",
            "Glove\n",
            "Epoch      8 | Loss: 0.416055 | time: 0m 0s\n",
            "Glove\n",
            "Epoch      9 | Loss: 0.385503 | time: 0m 0s\n",
            "Glove\n",
            "Epoch     10 | Loss: 1.280543 | time: 0m 0s\n",
            "Total runtime: 2.25 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embed(model, word):\n",
        "    try:\n",
        "        # Find the index\n",
        "        index = word2index[word]\n",
        "    except:\n",
        "        # if not found give the index of unknown token\n",
        "        index = word2index['<UNK>']\n",
        "\n",
        "    # get the word in terms of tensor\n",
        "    word = torch.LongTensor([word2index[word]])\n",
        "     # embed the center and the outside word and then find the final embed\n",
        "    embed_c = model.embedding_center(word)\n",
        "    embed_o = model.embedding_outside(word)\n",
        "    embed   = (embed_c + embed_o) / 2\n",
        "\n",
        "\n",
        "    return embed[0][0].item(), embed[0][1].item()\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def get_embed_for_corpus(model, words):\n",
        "    embeddings = {}\n",
        "\n",
        "    for word in words:\n",
        "        try:\n",
        "            index = word2index[word]\n",
        "        except KeyError:\n",
        "            index = word2index['<UNK>']\n",
        "\n",
        "        word_tensor = torch.LongTensor([index])\n",
        "\n",
        "        embed_c = model.embedding_center(word_tensor)\n",
        "        embed_o = model.embedding_outside(word_tensor)\n",
        "        embed = (embed_c + embed_o) / 2\n",
        "\n",
        "        # return as dictionary with key as the word and value as the array of its embedding\n",
        "        embeddings[word] = np.array([embed[0][0].item(), embed[0][1].item()])\n",
        "\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "ZSrI0m6-e0Zc"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#more formally is to divide by its norm\n",
        "def cosine_similarity(A, B):\n",
        "    dot_product = np.dot(A, B)\n",
        "    norm_a = np.linalg.norm(A)\n",
        "    norm_b = np.linalg.norm(B)\n",
        "    similarity = dot_product / (norm_a * norm_b)\n",
        "    return similarity\n",
        "def cosine_similarity_for_corpus(embeddings, target_word):\n",
        "    # List to store (word, cosine_similarity) pairs\n",
        "    similarities = []\n",
        "\n",
        "    # Get the index of the target word or use the index for '<UNK>' if not found\n",
        "    target_index = word2index.get(target_word, word2index['<UNK>'])\n",
        "\n",
        "    # Get the vector for the target word\n",
        "    target_vector = embeddings[target_index]\n",
        "\n",
        "    # Iterate through all words in the embeddings dictionary\n",
        "    for word, vector in embeddings.items():\n",
        "        # Calculate the cosine similarity between the target word and the current word\n",
        "        similarity = cosine_similarity(target_vector, vector)\n",
        "\n",
        "        # Append the (word, cosine_similarity) pair to the list\n",
        "        similarities.append((word, similarity))\n",
        "\n",
        "    return similarities"
      ],
      "metadata": {
        "id": "hM3LFMBfe4Gy"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to your .txt file\n",
        "file_path = 'word-test.v1 (1).txt'\n",
        "\n",
        "# Read the content of the file\n",
        "with open(file_path, 'r') as file:\n",
        "    # Skip the first line\n",
        "    file.readline()\n",
        "\n",
        "    # Read the remaining content of the file\n",
        "    file_content = file.readlines()\n",
        "\n",
        "# Initialize variables to store relevant lines\n",
        "total_corpus = []\n",
        "\n",
        "# Variable to keep track of the current heading\n",
        "current_heading = None\n",
        "\n",
        "# Iterate through each line in the file content\n",
        "for line in file_content:\n",
        "    # Check if the line is a heading\n",
        "    if line.startswith(':'):\n",
        "        current_heading = line.strip()\n",
        "    else:\n",
        "        # Split the line into individual words and convert to lowercase\n",
        "        words = [word.lower() for word in line.strip().split()]\n",
        "        total_corpus.append(words)"
      ],
      "metadata": {
        "id": "elTFD45Ge6yE"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'word-test.v1 (1).txt'\n",
        "\n",
        "# Read the content of the file\n",
        "with open(file_path, 'r') as file:\n",
        "    file_content = file.readlines()\n",
        "\n",
        "# Initialize variables to store relevant lines\n",
        "capital_common_countries = []\n",
        "past_tense = []\n",
        "\n",
        "# Variable to keep track of the current heading\n",
        "current_heading = None\n",
        "\n",
        "# Iterate through each line in the file content\n",
        "for line in file_content:\n",
        "    # Check if the line is a heading\n",
        "    if line.startswith(':'):\n",
        "        current_heading = line.strip()\n",
        "    elif current_heading == ': capital-common-countries':\n",
        "        # Split the line into individual words and convert to lowercase\n",
        "        words = [word.lower() for word in line.strip().split()]\n",
        "        capital_common_countries.append(words)\n",
        "    elif current_heading == ': gram7-past-tense':\n",
        "        # Split the line into individual words and convert to lowercase\n",
        "        words = [word.lower() for word in line.strip().split()]\n",
        "        past_tense.append(words)\n",
        ""
      ],
      "metadata": {
        "id": "QsPvC_PUe9aL"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the 2D list into a list of lists\n",
        "flattened_list_of_country = [word for pair in capital_common_countries for word in pair]\n",
        "\n",
        "# Wrap the flattened list in another list\n",
        "resulting_capital_list = [flattened_list_of_country]\n",
        "\n",
        "# Flatten the 2D list into a list of lists\n",
        "flattened_list_of_past_tense = [word for pair in past_tense for word in pair]\n",
        "\n",
        "# Wrap the flattened list in another list\n",
        "resulting_capital_list = [flattened_list_of_country]\n",
        "resulting_past_tense_list = [flattened_list_of_past_tense]\n",
        "\n",
        "# Flatten the 2D list into a list of lists\n",
        "flattened_list_total_words = [word for pair in total_corpus for word in pair]\n",
        "# Wrap the flattened list in another list\n",
        "resulting_total_corpus = [flattened_list_total_words]\n",
        "\n",
        "\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "capital_list = list(set(flatten(resulting_capital_list)))\n",
        "past_tense_list = list(set(flatten(resulting_past_tense_list)))\n",
        "whole_corpus = list(set(flatten(resulting_total_corpus)))"
      ],
      "metadata": {
        "id": "ih-PIUe5fC3Z"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the embeddings\n",
        "embed_capital_glove = get_embed_for_corpus(model_glove, capital_list)\n",
        "embed_capital_skipgram_positive = get_embed_for_corpus(model_skipgram_positive, capital_list)\n",
        "embed_capital_skipgram_negative = get_embed_for_corpus(model_skipgram_negative, capital_list)\n",
        "\n",
        "embed_past_tense_glove = get_embed_for_corpus(model_glove, past_tense_list)\n",
        "embed_past_tense_skipgram_positive = get_embed_for_corpus(model_skipgram_positive, past_tense_list)\n",
        "embed_past_tense_skipgram_negative = get_embed_for_corpus(model_skipgram_negative, past_tense_list)\n",
        "\n",
        "embed_total_glove = get_embed_for_corpus(model_glove, whole_corpus)\n",
        "embed_whole_skipgram_positive = get_embed_for_corpus(model_skipgram_positive, whole_corpus)\n",
        "embed_whole_skipgram_negative = get_embed_for_corpus(model_skipgram_negative, whole_corpus)\n",
        "# y_pred for glove for the capital list\n",
        "y_pred_glove_country = []\n",
        "\n",
        "for i in capital_common_countries:\n",
        "    y = embed_capital_glove[i[1]] - embed_capital_glove[i[0]] + embed_capital_glove[i[2]]\n",
        "    y_pred_glove_country.append(y)\n",
        "# y_pred for glove for the past tense list\n",
        "y_pred_glove_past = []\n",
        "\n",
        "for i in past_tense:\n",
        "    y = embed_past_tense_glove[i[1]] - embed_past_tense_glove[i[0]] + embed_past_tense_glove[i[2]]\n",
        "    y_pred_glove_past.append(y)\n",
        "# y_pred for skipgram negative sampling for the capital list\n",
        "y_pred_neg_samp_country = []\n",
        "\n",
        "for i in capital_common_countries:\n",
        "    y = embed_capital_skipgram_negative[i[1]] - embed_capital_skipgram_negative[i[0]] + embed_capital_skipgram_negative[i[2]]\n",
        "    y_pred_neg_samp_country.append(y)"
      ],
      "metadata": {
        "id": "oAv442BGfFny"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred for skipgram negative sampling for the past tense list\n",
        "y_pred_neg_samp_past = []\n",
        "\n",
        "for i in past_tense:\n",
        "    y = embed_past_tense_skipgram_negative[i[0]] - embed_past_tense_skipgram_negative[i[0]] + embed_past_tense_skipgram_negative[i[2]]\n",
        "    y_pred_neg_samp_past.append(y)\n",
        "# y_pred for skipgram positive sampling for the country list\n",
        "y_pred_positive_samp_country = []\n",
        "\n",
        "for i in capital_common_countries:\n",
        "    y = embed_capital_skipgram_positive[i[1]] - embed_capital_skipgram_positive[i[0]] + embed_capital_skipgram_positive[i[2]]\n",
        "    y_pred_positive_samp_country.append(y)\n",
        "# y_pred for skipgram positive sampling for the past tense list\n",
        "y_pred_positive_past_tense = []\n",
        "\n",
        "for i in past_tense:\n",
        "    y = embed_past_tense_skipgram_positive[i[1]] - embed_past_tense_skipgram_positive[i[0]] + embed_past_tense_skipgram_positive[i[2]]\n",
        "    y_pred_positive_past_tense.append(y)\n",
        "# find the cosine similarity\n",
        "#more formally is to divide by its norm\n",
        "def cosine_similarity(A, B):\n",
        "    dot_product = np.dot(A, B)\n",
        "    norm_a = np.linalg.norm(A)\n",
        "    norm_b = np.linalg.norm(B)\n",
        "    similarity = dot_product / (norm_a * norm_b)\n",
        "    return similarity\n",
        "def find_max_cosine_words(y_pred, embeddings):\n",
        "    \"\"\"\n",
        "    Find the word with the maximum cosine similarity for each vector in y_pred.\n",
        "\n",
        "    Parameters:\n",
        "    - y_pred: List of vectors for which to find the max cosine similarity words.\n",
        "    - embeddings: Dictionary of word embeddings.\n",
        "\n",
        "    Returns:\n",
        "    - List of words with the maximum cosine similarity for each vector in y_pred.\n",
        "    \"\"\"\n",
        "    max_cosine_words = []\n",
        "\n",
        "    for j in range(len(y_pred)):\n",
        "        max_cosine = -1\n",
        "        max_cosine_word = \"\"\n",
        "\n",
        "        for i in embeddings.keys():\n",
        "            cosine_temp = cosine_similarity(y_pred[j], embeddings[i])\n",
        "\n",
        "            if cosine_temp > max_cosine:\n",
        "                max_cosine_word = i\n",
        "                max_cosine = cosine_temp\n",
        "\n",
        "        max_cosine_words.append(max_cosine_word)\n",
        "\n",
        "    return max_cosine_words\n",
        "\n",
        "#Usage\n",
        "cosine_neg_samp_syntatical = find_max_cosine_words(y_pred_neg_samp_country, embed_capital_skipgram_negative)\n",
        "cosine_positive_samp_syntatical = find_max_cosine_words(y_pred_positive_samp_country, embed_capital_skipgram_positive)\n",
        "cosine_glove_syntatical = find_max_cosine_words(y_pred_glove_country, embed_capital_glove)\n",
        "from heapq import nlargest\n",
        "\n",
        "def find_next_10_cosine_words_for_word(target_word, embeddings, top_n=10):\n",
        "    \"\"\"\n",
        "    Find the next 10 words with the maximum cosine similarity for a user-provided specific word.\n",
        "\n",
        "    Parameters:\n",
        "    - target_word: The word for which to find the next 10 cosine similarity words.\n",
        "    - embeddings: Dictionary of word embeddings.\n",
        "    - top_n: Number of top words to retrieve for the target word (default is 10).\n",
        "\n",
        "    Returns:\n",
        "    - List of the next 10 words with the maximum cosine similarity for the target word or [\"Word not in Corpus\"].\n",
        "    \"\"\"\n",
        "    if target_word not in embeddings:\n",
        "        return [\"Word not in Corpus\"]\n",
        "\n",
        "    target_vector = embeddings[target_word]\n",
        "    cosine_similarities = [(word, cosine_similarity(target_vector, embeddings[word])) for word in embeddings.keys()]\n",
        "    top_n_words = nlargest(top_n + 1, cosine_similarities, key=lambda x: x[1])\n",
        "\n",
        "    # Exclude the target word itself\n",
        "    top_n_words = [word for word, _ in top_n_words if word != target_word]\n",
        "\n",
        "    return top_n_words[:10]\n",
        "\n",
        "# Usage:\n",
        "user_target_word = 'greece'\n",
        "next_10_cosine_for_user_word = find_next_10_cosine_words_for_word(user_target_word, embed_whole_skipgram_negative, top_n=10)\n",
        "\n",
        "# Print the results\n",
        "if next_10_cosine_for_user_word == [\"Word not in Corpus\"]:\n",
        "    print(\"Word not in Corpus\")\n",
        "else:\n",
        "    print(f\"Next 10 similar words for user-provided word '{user_target_word}': {next_10_cosine_for_user_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIVT0Q-HfIFB",
        "outputId": "ba3c88aa-30c6-4312-bf49-f958646f741a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next 10 similar words for user-provided word 'greece': ['great', 'heavy', 'impressive', 'building', 'reasonable', 'bad', 'garland', 'india', 'buildings', 'unpleasant']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(predictions, true_words):\n",
        "    \"\"\"\n",
        "    Calculate accuracy based on predictions and true words.\n",
        "\n",
        "    Parameters:\n",
        "    - predictions: List of predicted words.\n",
        "    - true_words: List of true words.\n",
        "\n",
        "    Returns:\n",
        "    - Accuracy as a percentage.\n",
        "    \"\"\"\n",
        "    total_trials = len(predictions)\n",
        "    total_correct = sum(1 for pred_word in predictions if pred_word in true_words)\n",
        "\n",
        "    accuracy = (total_correct / total_trials) * 100\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Usage:\n",
        "semantic_accuracy_neg_samp = calculate_accuracy(find_max_cosine_words(y_pred_neg_samp_country, embed_whole_skipgram_negative), [true_word[3] for true_word in capital_common_countries])\n",
        "semantic_accuracy_pos_samp = calculate_accuracy(find_max_cosine_words(y_pred_positive_samp_country, embed_whole_skipgram_positive), [true_word[3] for true_word in capital_common_countries])\n",
        "semantic_accuracy_glove = calculate_accuracy(find_max_cosine_words(y_pred_glove_country, embed_total_glove), [true_word[3] for true_word in capital_common_countries])\n",
        "print(\"Semantic Accuracy of Skipgram Negative: {:.10f}%\".format(semantic_accuracy_neg_samp))\n",
        "print(\"Semantic Accuracy of Skipgram Positive: {:.10f}%\".format(semantic_accuracy_pos_samp))\n",
        "print(\"Semantic Accuracy of Glove: {:.10f}%\".format(semantic_accuracy_glove))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mwGOctufKlf",
        "outputId": "e47e8b54-9263-4d45-c613-c7cf12b65f1b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semantic Accuracy of Skipgram Negative: 14.4268774704%\n",
            "Semantic Accuracy of Skipgram Positive: 14.2292490119%\n",
            "Semantic Accuracy of Glove: 14.8221343874%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_file_path = 'word-test.v1 (1).txt'\n",
        "output_file_path = 'word-test-without-first-line.txt'\n",
        "\n",
        "# Open the input file for reading\n",
        "with open(input_file_path, 'r', encoding='utf-8') as input_file:\n",
        "    # Read all lines from the input file\n",
        "    lines = input_file.readlines()\n",
        "\n",
        "# Open the output file for writing\n",
        "with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "    # Write all lines except the first line to the output file\n",
        "    output_file.writelines(lines[1:])\n",
        "\n",
        "print(f\"First line removed and content saved to: {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYliyRHQfOp1",
        "outputId": "4e6675aa-f7f8-4d16-f690-6edf58c0d9fa"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First line removed and content saved to: word-test-without-first-line.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_file_path = 'word-test.v1 (1).txt'\n",
        "output_file_path = 'capital.txt'\n",
        "\n",
        "# Open the input file for reading\n",
        "with open(input_file_path, 'r', encoding='utf-8') as input_file:\n",
        "    # Read all lines from the input file\n",
        "    lines = input_file.readlines()\n",
        "\n",
        "# Open the output file for writing\n",
        "with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "    # Flag to indicate whether to start writing lines\n",
        "    start_writing = False\n",
        "\n",
        "    # Iterate through lines\n",
        "    for line in lines:\n",
        "        # Check if the line starts with ': gram7-past-tense'\n",
        "        if line.startswith(': capital-common-countries'):\n",
        "            # Set the flag to start writing\n",
        "            start_writing = True\n",
        "        elif line.startswith(':'):\n",
        "            # If a new section header is encountered, stop writing\n",
        "            start_writing = False\n",
        "\n",
        "        # Write lines to the output file if the flag is True\n",
        "        if start_writing:\n",
        "            output_file.write(line)\n",
        "\n",
        "print(f\"Lines starting with ': capital-countries' saved to: {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odo6LQlTfRny",
        "outputId": "c003a59e-2c9f-415e-d3f3-56a92e003210"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines starting with ': capital-countries' saved to: capital.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analogy_score_sem = model_gensim.evaluate_word_analogies(datapath('/content/capital.txt'))\n",
        "print(\"Semtatical Accuracy of Model Gensim:\", analogy_score_sem[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os7J8VO6fU_m",
        "outputId": "2927ff9e-dde7-487f-febb-25d2258bcd29"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semtatical Accuracy of Model Gensim: 0.9387351778656127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(predictions, true_words):\n",
        "    \"\"\"\n",
        "    Calculate accuracy based on predictions and true words.\n",
        "\n",
        "    Parameters:\n",
        "    - predictions: List of predicted words.\n",
        "    - true_words: List of true words.\n",
        "\n",
        "    Returns:\n",
        "    - Accuracy as a percentage.\n",
        "    \"\"\"\n",
        "    total_trials = len(predictions)\n",
        "    total_correct = sum(1 for pred_word in predictions if pred_word in true_words)\n",
        "\n",
        "    accuracy = (total_correct / total_trials) * 100\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Usage:\n",
        "syntatical_accuracy_neg_samp = calculate_accuracy(find_max_cosine_words(y_pred_neg_samp_past, embed_whole_skipgram_negative), [true_word[3] for true_word in past_tense])\n",
        "syntatical_accuracy_pos_samp = calculate_accuracy(find_max_cosine_words(y_pred_positive_past_tense, embed_whole_skipgram_positive), [true_word[3] for true_word in past_tense])\n",
        "syntatical_accuracy_glove = calculate_accuracy(find_max_cosine_words(y_pred_glove_past, embed_total_glove), [true_word[3] for true_word in past_tense])\n",
        "print(\"Syntatical Accuracy of Skipgram Negative: {:.2f}%\".format(syntatical_accuracy_neg_samp))\n",
        "print(\"Syntatical Accuracy of Skipgram Positive: {:.2f}%\".format(syntatical_accuracy_pos_samp))\n",
        "print(\"Syntatical Accuracy of Glove: {:.2f}%\".format(syntatical_accuracy_glove))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww4eeYy_fYJm",
        "outputId": "0fb8ef53-1eb6-4b6b-d4df-658e66025c9b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Syntatical Accuracy of Skipgram Negative: 0.00%\n",
            "Syntatical Accuracy of Skipgram Positive: 17.37%\n",
            "Syntatical Accuracy of Glove: 10.83%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_file_path = 'word-test.v1 (1).txt'\n",
        "output_file_path = 'past_tense_lines.txt'\n",
        "\n",
        "# Open the input file for reading\n",
        "with open(input_file_path, 'r', encoding='utf-8') as input_file:\n",
        "    # Read all lines from the input file\n",
        "    lines = input_file.readlines()\n",
        "\n",
        "# Open the output file for writing\n",
        "with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "    # Flag to indicate whether to start writing lines\n",
        "    start_writing = False\n",
        "\n",
        "    # Iterate through lines\n",
        "    for line in lines:\n",
        "        # Check if the line starts with ': gram7-past-tense'\n",
        "        if line.startswith(': gram7-past-tense'):\n",
        "            # Set the flag to start writing\n",
        "            start_writing = True\n",
        "        elif line.startswith(':'):\n",
        "            # If a new section header is encountered, stop writing\n",
        "            start_writing = False\n",
        "\n",
        "        # Write lines to the output file if the flag is True\n",
        "        if start_writing:\n",
        "            output_file.write(line)\n",
        "\n",
        "print(f\"Lines starting with ': gram7-past-tense' saved to: {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IfFb6mffekV",
        "outputId": "69b01691-1907-4b15-fa13-65d93f7c693e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines starting with ': gram7-past-tense' saved to: past_tense_lines.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analogy_score_syn = model_gensim.evaluate_word_analogies(datapath('/content/past_tense_lines.txt'))\n",
        "print(\"Syntatical Accuracy of Model Gensim:\", analogy_score_syn[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dhgJVwQfg_j",
        "outputId": "465283f2-24a3-47e4-cb9e-ebdf41a9955d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Syntatical Accuracy of Model Gensim: 0.5544871794871795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = 'wordsim_similarity_goldstandard.txt'\n",
        "\n",
        "# Define the column names\n",
        "columns = ['word_1', 'word_2', 'similarity_index']\n",
        "\n",
        "# Read the text file into a pandas DataFrame with specified column names\n",
        "df = pd.read_csv(file_path, sep='\\t', header=None, names=columns)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "UjXyIQQNfoOK",
        "outputId": "4d20a78d-3661-422a-ef6c-4cf8d868d163"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         word_1    word_2  similarity_index\n",
              "0         tiger       cat              7.35\n",
              "1         tiger     tiger             10.00\n",
              "2         plane       car              5.77\n",
              "3         train       car              6.31\n",
              "4    television     radio              6.77\n",
              "..          ...       ...               ...\n",
              "198     rooster    voyage              0.62\n",
              "199        noon    string              0.54\n",
              "200       chord     smile              0.54\n",
              "201   professor  cucumber              0.31\n",
              "202        king   cabbage              0.23\n",
              "\n",
              "[203 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b62b717-e220-4e04-a703-2acbd468535c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_1</th>\n",
              "      <th>word_2</th>\n",
              "      <th>similarity_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tiger</td>\n",
              "      <td>cat</td>\n",
              "      <td>7.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tiger</td>\n",
              "      <td>tiger</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>plane</td>\n",
              "      <td>car</td>\n",
              "      <td>5.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train</td>\n",
              "      <td>car</td>\n",
              "      <td>6.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>television</td>\n",
              "      <td>radio</td>\n",
              "      <td>6.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>rooster</td>\n",
              "      <td>voyage</td>\n",
              "      <td>0.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>noon</td>\n",
              "      <td>string</td>\n",
              "      <td>0.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>chord</td>\n",
              "      <td>smile</td>\n",
              "      <td>0.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>professor</td>\n",
              "      <td>cucumber</td>\n",
              "      <td>0.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>king</td>\n",
              "      <td>cabbage</td>\n",
              "      <td>0.23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>203 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b62b717-e220-4e04-a703-2acbd468535c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7b62b717-e220-4e04-a703-2acbd468535c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7b62b717-e220-4e04-a703-2acbd468535c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2928a27a-b9e3-46d5-a842-1a6505b48e5e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2928a27a-b9e3-46d5-a842-1a6505b48e5e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2928a27a-b9e3-46d5-a842-1a6505b48e5e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ea931f88-9940-48ea-b06c-bf02649fbc32\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ea931f88-9940-48ea-b06c-bf02649fbc32 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 203,\n  \"fields\": [\n    {\n      \"column\": \"word_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 130,\n        \"samples\": [\n          \"marathon\",\n          \"century\",\n          \"vodka\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 177,\n        \"samples\": [\n          \"Jackson\",\n          \"fauna\",\n          \"interview\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"similarity_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.5039610876799423,\n        \"min\": 0.23,\n        \"max\": 10.0,\n        \"num_unique_values\": 150,\n        \"samples\": [\n          8.34,\n          6.63,\n          3.04\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_embed(model_skipgram_negative,'<UNK>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2APWjUGefrFY",
        "outputId": "c613493e-bcfd-442c-92ce-605c7ea688df"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.9422623515129089, -0.24112652242183685)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through each row in the DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    word_1 = row['word_1']\n",
        "    word_2 = row['word_2']\n",
        "\n",
        "    try:\n",
        "        # Attempt to get embeddings and compute the dot product\n",
        "        embed_1_neg_samp = get_embed(model_skipgram_negative, word_1)\n",
        "        embed_2_neg_samp = get_embed(model_skipgram_negative, word_2)\n",
        "        embed_1_pos_samp = get_embed(model_skipgram_positive, word_1)\n",
        "        embed_2_pos_samp = get_embed(model_skipgram_positive, word_2)\n",
        "        embed_1_glove = get_embed(model_glove, word_1)\n",
        "        embed_2_glove = get_embed(model_glove, word_2)\n",
        "\n",
        "    except KeyError:\n",
        "        # Handle the case where one or both words are not present in the model\n",
        "        # Replace missing embeddings with the embedding of '<UNK>' or any other suitable value\n",
        "        embed_1_neg_samp = get_embed(model_skipgram_negative, '<UNK>')\n",
        "        embed_2_neg_samp = get_embed(model_skipgram_negative, '<UNK>')\n",
        "        embed_1_pos_samp = get_embed(model_skipgram_positive, '<UNK>')\n",
        "        embed_2_pos_samp = get_embed(model_skipgram_positive, '<UNK>')\n",
        "        embed_1_glove = get_embed(model_glove, '<UNK>')\n",
        "        embed_2_glove = get_embed(model_glove, '<UNK>')\n",
        "\n",
        "    # Compute the dot product and update the DataFrame\n",
        "    df.at[index, 'dot_product_neg_samp'] = np.dot(embed_1_neg_samp, embed_2_neg_samp)\n",
        "    df.at[index, 'dot_product_pos_samp'] = np.dot(embed_1_pos_samp, embed_2_pos_samp)\n",
        "    df.at[index, 'dot_product_glove'] = np.dot(embed_1_glove, embed_2_glove)\n",
        "\n",
        "df[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "gODtAsVDftWX",
        "outputId": "2faf83f4-17b8-4409-cdc3-af671ccdcfdc"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       word_1  word_2  similarity_index  dot_product_neg_samp  \\\n",
              "0       tiger     cat              7.35              0.946000   \n",
              "1       tiger   tiger             10.00              0.946000   \n",
              "2       plane     car              5.77              0.946000   \n",
              "3       train     car              6.31              0.946000   \n",
              "4  television   radio              6.77              0.018226   \n",
              "5       media   radio              7.42              0.946000   \n",
              "6       bread  butter              6.19              0.946000   \n",
              "7    cucumber  potato              5.92              0.946000   \n",
              "8      doctor   nurse              7.00              0.233670   \n",
              "9   professor  doctor              6.62             -0.159331   \n",
              "\n",
              "   dot_product_pos_samp  dot_product_glove  \n",
              "0              1.831255           0.166877  \n",
              "1              1.831255           0.166877  \n",
              "2              1.831255           0.166877  \n",
              "3              1.831255           0.166877  \n",
              "4              0.142152           0.206279  \n",
              "5              1.831255           0.166877  \n",
              "6              1.831255           0.166877  \n",
              "7              1.831255           0.166877  \n",
              "8             -0.415449           0.505031  \n",
              "9             -0.994806          -0.334666  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7620ce82-5e29-4019-b0e0-e341789140d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_1</th>\n",
              "      <th>word_2</th>\n",
              "      <th>similarity_index</th>\n",
              "      <th>dot_product_neg_samp</th>\n",
              "      <th>dot_product_pos_samp</th>\n",
              "      <th>dot_product_glove</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tiger</td>\n",
              "      <td>cat</td>\n",
              "      <td>7.35</td>\n",
              "      <td>0.946000</td>\n",
              "      <td>1.831255</td>\n",
              "      <td>0.166877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tiger</td>\n",
              "      <td>tiger</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0.946000</td>\n",
              "      <td>1.831255</td>\n",
              "      <td>0.166877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>plane</td>\n",
              "      <td>car</td>\n",
              "      <td>5.77</td>\n",
              "      <td>0.946000</td>\n",
              "      <td>1.831255</td>\n",
              "      <td>0.166877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train</td>\n",
              "      <td>car</td>\n",
              "      <td>6.31</td>\n",
              "      <td>0.946000</td>\n",
              "      <td>1.831255</td>\n",
              "      <td>0.166877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>television</td>\n",
              "      <td>radio</td>\n",
              "      <td>6.77</td>\n",
              "      <td>0.018226</td>\n",
              "      <td>0.142152</td>\n",
              "      <td>0.206279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>media</td>\n",
              "      <td>radio</td>\n",
              "      <td>7.42</td>\n",
              "      <td>0.946000</td>\n",
              "      <td>1.831255</td>\n",
              "      <td>0.166877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>bread</td>\n",
              "      <td>butter</td>\n",
              "      <td>6.19</td>\n",
              "      <td>0.946000</td>\n",
              "      <td>1.831255</td>\n",
              "      <td>0.166877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>cucumber</td>\n",
              "      <td>potato</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.946000</td>\n",
              "      <td>1.831255</td>\n",
              "      <td>0.166877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>doctor</td>\n",
              "      <td>nurse</td>\n",
              "      <td>7.00</td>\n",
              "      <td>0.233670</td>\n",
              "      <td>-0.415449</td>\n",
              "      <td>0.505031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>professor</td>\n",
              "      <td>doctor</td>\n",
              "      <td>6.62</td>\n",
              "      <td>-0.159331</td>\n",
              "      <td>-0.994806</td>\n",
              "      <td>-0.334666</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7620ce82-5e29-4019-b0e0-e341789140d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7620ce82-5e29-4019-b0e0-e341789140d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7620ce82-5e29-4019-b0e0-e341789140d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-68d7b8e1-25c3-48f7-9ca4-8f5a1ea8dfe2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-68d7b8e1-25c3-48f7-9ca4-8f5a1ea8dfe2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-68d7b8e1-25c3-48f7-9ca4-8f5a1ea8dfe2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[:10]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"word_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"doctor\",\n          \"plane\",\n          \"bread\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"tiger\",\n          \"potato\",\n          \"cat\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"similarity_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2140588490221094,\n        \"min\": 5.77,\n        \"max\": 10.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          7.0,\n          10.0,\n          7.42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dot_product_neg_samp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4516876260841383,\n        \"min\": -0.15933143716107967,\n        \"max\": 0.9460003388938854,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.01822635137414963,\n          -0.15933143716107967,\n          0.9460003388938854\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dot_product_pos_samp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1212630994442516,\n        \"min\": -0.9948059520811086,\n        \"max\": 1.8312545757522827,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.14215157215147656,\n          -0.9948059520811086,\n          1.8312545757522827\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dot_product_glove\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20163458242118354,\n        \"min\": -0.3346655900275124,\n        \"max\": 0.5050313063718095,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.2062790132135186,\n          -0.3346655900275124,\n          0.16687688365468745\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import spearmanr\n",
        "\n",
        "# Compute the Spearman correlation between the provided similarity scores and your models' dot products\n",
        "correlation_neg, _ = spearmanr(df['similarity_index'], df['dot_product_neg_samp'])\n",
        "correlation_pos, _ = spearmanr(df['similarity_index'], df['dot_product_pos_samp'])\n",
        "correlation_glove, _ = spearmanr(df['similarity_index'], df['dot_product_glove'])\n",
        "\n",
        "\n",
        "# Display the correlation coefficient\n",
        "print(f\"Spearman Correlation Coefficient of Skipgram Negative: {correlation_neg:.4f}\")\n",
        "print(f\"Spearman Correlation Coefficient of Skipgram Positive: {correlation_pos:.4f}\")\n",
        "print(f\"Spearman Correlation Coefficient of Glove: {correlation_glove:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPj6OSrdfwC1",
        "outputId": "7e0f7c3f-4b7c-477a-8152-ad267475706e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spearman Correlation Coefficient of Skipgram Negative: 0.0232\n",
            "Spearman Correlation Coefficient of Skipgram Positive: 0.0153\n",
            "Spearman Correlation Coefficient of Glove: -0.0711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding y_true based on the mean of similarity index in the df\n",
        "y_true = df['similarity_index'].mean()\n",
        "\n",
        "print(f\"y_true: {y_true:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltMA-uVnf0yh",
        "outputId": "f6459407-93a0-4a20-ea97-1e862b4cb328"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_true: 5.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the correlation coeffiecient of the gensim model using the predefined function\n",
        "correlation_coefficient = model_gensim.evaluate_word_pairs(datapath('/content/wordsim_similarity_goldstandard.txt'))\n",
        "print(f\"Correlation coefficient: {correlation_coefficient[1][0]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35pggBCpf3_C",
        "outputId": "ffd1fbe9-dbf2-4345-dd14-2bb549f66880"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation coefficient: 0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_whole_glove = get_embed_for_corpus(model_glove, vocab)\n",
        "embed_whole_neg_skg = get_embed_for_corpus(model_skipgram_negative, vocab)\n",
        "embed_whole_pos_skg = get_embed_for_corpus(model_skipgram_positive, vocab)"
      ],
      "metadata": {
        "id": "uXvbPMfmf6jg"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming you have a Gensim Word2Vec model named 'model'\n",
        "# You can replace 'Word2Vec' with the specific Gensim model you are using\n",
        "\n",
        "# Save the Gensim model to a file using pickle\n",
        "gensim_model_path = 'model_gensim.pkl'\n",
        "\n",
        "with open(gensim_model_path, 'wb') as model_file:\n",
        "    pickle.dump(model_gensim, model_file)\n",
        "\n",
        "print(f\"Gensim model saved to: {gensim_model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUqbFnGvgKEP",
        "outputId": "c0e20a87-6b5e-4187-d289-8451e9dacc07"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gensim model saved to: model_gensim.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to your pickled Gensim model file\n",
        "gensim_model_path = 'model_gensim.pkl'\n",
        "\n",
        "# Load the Gensim model from the pickle file\n",
        "with open(gensim_model_path, 'rb') as model_file:\n",
        "    loaded_model = pickle.load(model_file)\n",
        "for i in range (1,10):\n",
        "    print(loaded_model.most_similar('language')[i][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoAFRFV2gMSp",
        "outputId": "feda00dc-c4c4-4972-a1a4-b2a0ae904c39"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word\n",
            "spoken\n",
            "arabic\n",
            "english\n",
            "dialect\n",
            "vocabulary\n",
            "text\n",
            "translation\n",
            "words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming embed_capital_skipgram_negative is your embedding dictionary\n",
        "embedding_dict = embed_whole_pos_skg\n",
        "\n",
        "# Specify the file path to save the pickle file\n",
        "pickle_file_path = 'embed_skipgram_positive.pkl'\n",
        "\n",
        "# Open the file in binary write mode and dump the dictionary\n",
        "with open(pickle_file_path, 'wb') as pickle_file:\n",
        "    pickle.dump(embedding_dict, pickle_file)\n",
        "\n",
        "print(f\"Embedding dictionary saved to: {pickle_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdYCQBD3gOdj",
        "outputId": "850b84cf-6331-416d-cbdd-6d1f63e638e2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding dictionary saved to: embed_skipgram_positive.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming embed_capital_skipgram_negative is your embedding dictionary\n",
        "embedding_dict = embed_whole_neg_skg\n",
        "\n",
        "# Specify the file path to save the pickle file\n",
        "pickle_file_path = 'embed_skipgram_negative.pkl'\n",
        "\n",
        "# Open the file in binary write mode and dump the dictionary\n",
        "with open(pickle_file_path, 'wb') as pickle_file:\n",
        "    pickle.dump(embedding_dict, pickle_file)\n",
        "\n",
        "print(f\"Embedding dictionary saved to: {pickle_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sszKNQF4gQUl",
        "outputId": "6739e8ff-a881-4acd-dc90-22c854947de9"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding dictionary saved to: embed_skipgram_negative.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming embed_capital_skipgram_negative is your embedding dictionary\n",
        "embedding_dict = embed_whole_glove\n",
        "\n",
        "# Specify the file path to save the pickle file\n",
        "pickle_file_path = 'embed_glove.pkl'\n",
        "\n",
        "# Open the file in binary write mode and dump the dictionary\n",
        "with open(pickle_file_path, 'wb') as pickle_file:\n",
        "    pickle.dump(embedding_dict, pickle_file)\n",
        "\n",
        "print(f\"Embedding dictionary saved to: {pickle_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFJ8p4BGgS5h",
        "outputId": "81ce0aa0-a66b-475c-9b2b-7f5e217763d5"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding dictionary saved to: embed_glove.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Specify the path to the pickled file on the server\n",
        "pickle_file_path = 'embed_skipgram_positive.pkl'\n",
        "\n",
        "# Load the embedding dictionary from the pickled file\n",
        "with open(pickle_file_path, 'rb') as pickle_file:\n",
        "    embedding_dict_neg = pickle.load(pickle_file)\n",
        "import pickle\n",
        "\n",
        "# Specify the path to the pickled file on the server\n",
        "pickle_file_path = 'embed_skipgram_negative.pkl'\n",
        "\n",
        "# Load the embedding dictionary from the pickled file\n",
        "with open(pickle_file_path, 'rb') as pickle_file:\n",
        "    embedding_dict_pos = pickle.load(pickle_file)\n",
        "import pickle\n",
        "\n",
        "# Specify the path to the pickled file on the server\n",
        "pickle_file_path = 'embed_glove.pkl'\n",
        "\n",
        "# Load the embedding dictionary from the pickled file\n",
        "with open(pickle_file_path, 'rb') as pickle_file:\n",
        "    embedding_dict_glove = pickle.load(pickle_file)\n",
        "user_target_word = \"run\"\n",
        "next_10_cosine_for_user_word = find_next_10_cosine_words_for_word(user_target_word, embedding_dict_glove, top_n=10)\n",
        "\n",
        "# Print the results\n",
        "if next_10_cosine_for_user_word == [\"Word not in Corpus\"]:\n",
        "    print(\"Word not in Corpus\")\n",
        "else:\n",
        "    print(f\"Next 10 similar words for user-provided word '{user_target_word}': {next_10_cosine_for_user_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq0yaUzggU6x",
        "outputId": "32eeffe3-e83e-4938-9acc-0445376bd5ea"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next 10 similar words for user-provided word 'run': ['workshop', 'math', 'powers', 'super', 'research', 'value', 'trial', 'determine', 'bigger', 'hackett']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAUnC-wfgaRo",
        "outputId": "01010a47-8c03-4d7a-8ec4-e90058c7f969"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.21.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.41.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "\n",
        "# Define function to calculate cosine similarity\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    \"\"\"Calculate the cosine similarity between two vectors.\"\"\"\n",
        "    dot_product = np.dot(vec1, vec2)\n",
        "    norm_vec1 = np.linalg.norm(vec1)\n",
        "    norm_vec2 = np.linalg.norm(vec2)\n",
        "    return dot_product / (norm_vec1 * norm_vec2) if norm_vec1 != 0 and norm_vec2 != 0 else 0.0\n",
        "\n",
        "# Load the embedding dictionaries\n",
        "def load_embeddings():\n",
        "    pickle_file_path_pos = 'embed_skipgram_positive.pkl'\n",
        "    pickle_file_path_neg = 'embed_skipgram_negative.pkl'\n",
        "    pickle_file_path_glove = 'embed_glove.pkl'\n",
        "\n",
        "    with open(pickle_file_path_pos, 'rb') as file:\n",
        "        embedding_dict_pos = pickle.load(file)\n",
        "    with open(pickle_file_path_neg, 'rb') as file:\n",
        "        embedding_dict_neg = pickle.load(file)\n",
        "    with open(pickle_file_path_glove, 'rb') as file:\n",
        "        embedding_dict_glove = pickle.load(file)\n",
        "\n",
        "    return embedding_dict_pos, embedding_dict_neg, embedding_dict_glove\n",
        "\n",
        "# Function to find next 10 similar words based on cosine similarity\n",
        "def find_next_10_cosine_words_for_word(target_word, embedding_dict, top_n=10):\n",
        "    if target_word not in embedding_dict:\n",
        "        return [\"Word not in Corpus\"]\n",
        "\n",
        "    target_vector = embedding_dict[target_word]\n",
        "    similarities = []\n",
        "\n",
        "    for word, vector in embedding_dict.items():\n",
        "        if word != target_word:  # Skip the target word itself\n",
        "            sim = cosine_similarity(target_vector, vector)\n",
        "            similarities.append((word, sim))\n",
        "\n",
        "    # Sort the words based on similarity (highest first)\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Return the top N similar words\n",
        "    return [word for word, _ in similarities[:top_n]]\n",
        "\n",
        "# Streamlit app interface\n",
        "def main():\n",
        "    # Load embeddings at the start\n",
        "    embedding_dict_pos, embedding_dict_neg, embedding_dict_glove = load_embeddings()\n",
        "\n",
        "    # Set up the Streamlit app title and description\n",
        "    st.title(\"Word Similarity Search\")\n",
        "    st.write(\"Enter a word to find the next 10 most similar words based on cosine similarity.\")\n",
        "\n",
        "    # Get user input for the target word\n",
        "    user_target_word = st.text_input(\"Enter a word to search:\", \"run\")  # Default word is \"run\"\n",
        "\n",
        "    # Select the embedding model to use\n",
        "    model_choice = st.selectbox(\"Select Embedding Model\", [\"GloVe\", \"Skipgram Positive\", \"Skipgram Negative\"])\n",
        "\n",
        "    # Based on the model choice, select the appropriate embedding dictionary\n",
        "    if model_choice == \"GloVe\":\n",
        "        embedding_dict = embedding_dict_glove\n",
        "    elif model_choice == \"Skipgram Positive\":\n",
        "        embedding_dict = embedding_dict_pos\n",
        "    elif model_choice == \"Skipgram Negative\":\n",
        "        embedding_dict = embedding_dict_neg\n",
        "\n",
        "    # If the user entered a word, compute the top 10 similar words\n",
        "    if user_target_word:\n",
        "        with st.spinner('Finding similar words...'):\n",
        "            next_10_cosine_for_user_word = find_next_10_cosine_words_for_word(user_target_word, embedding_dict, top_n=10)\n",
        "\n",
        "            # Display results\n",
        "            if next_10_cosine_for_user_word == [\"Word not in Corpus\"]:\n",
        "                st.error(\"Word not in Corpus\")\n",
        "            else:\n",
        "                st.success(f\"Top 10 similar words for '{user_target_word}':\")\n",
        "                st.write(next_10_cosine_for_user_word)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkzA-e7kga9w",
        "outputId": "b05bebe8-ce45-4476-f88e-97b40f3b0939"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-18 13:02:41.472 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:41.848 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-01-18 13:02:41.852 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:41.854 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:41.857 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:41.859 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:41.861 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:41.866 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:41.868 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:41.875 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:41.885 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:41.887 Session state does not function when running a script without `streamlit run`\n",
            "2025-01-18 13:02:41.888 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:41.894 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:41.895 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:41.901 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:41.902 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:41.906 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:41.907 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:41.909 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:41.911 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:41.915 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:41.916 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:42.019 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:42.025 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:42.030 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:42.035 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:42.039 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-18 13:02:42.062 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wCT35uRJgjRO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}